{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Dealing with Categorical Variables.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Ul9alnq6CijQEKtFjfRMmsdiqRGN2vg-",
      "authorship_tag": "ABX9TyPohIoAjBuI+Zwc+VJbHxGu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cirilwakounig/MachineLearning/blob/main/3_Dealing_with_Categorical_Variables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOrnVotduYiq"
      },
      "source": [
        "# Dealing with Categorical Variables\r\n",
        "\r\n",
        "This script is showing how to effectively deal with categorical variables. More information about methods and strategies can be found here: https://www.kaggle.com/alexisbcook/categorical-variables. This script is based on the course 'Intermediate Machine Learning' provided by Kaggle. \r\n",
        "\r\n",
        "Categorical Values can be dealt with using three different approaches:\r\n",
        "\r\n",
        "1. Dropping the columns, in case they do not contain useful information\r\n",
        "2. Label Encoding, which is ordering the labels - Useful for data that can be ranked (ordinal data)\r\n",
        "3. One-Hot Encoding, which is used for data that cannot be ranked (nominal data) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xvAALunuTkq"
      },
      "source": [
        "# Import the required Libraries\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# Data Processing\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "\r\n",
        "# Model Development and Validation\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vSa6KAMvtDf"
      },
      "source": [
        "##### 1. Import and Process the required Data\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MKjLmE-qskI"
      },
      "source": [
        "##### 1.1 Import of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1yKn1sdvxcL"
      },
      "source": [
        "# Import the Data Set Set\r\n",
        "file_path_train = '/content/drive/MyDrive/Colab Notebooks/Kaggle Course/Intermediate Machine Learning/melb_data.csv'\r\n",
        "# file_path_test = '/content/drive/MyDrive/Colab Notebooks/Kaggle Course/Intermediate Machine Learning/test.csv'\r\n",
        "\r\n",
        "# Read the data\r\n",
        "X_full = pd.read_csv(file_path_train)\r\n",
        "# X_test_full = pd.read_csv(file_path_test, index_col = 'Id')\r\n",
        "\r\n",
        "# Assign the dependent variable - Remove missing target values\r\n",
        "X_full.dropna(axis = 0, subset = ['Price'], inplace = True)   # Inplace = True overrides existing data frame\r\n",
        "y = X_full.Price\r\n",
        "\r\n",
        "# Separate features from predictors\r\n",
        "X = X_full.drop(['Price'], axis = 1)\r\n",
        "\r\n",
        "# Drop Columns with missing values (easier approach)\r\n",
        "drop_cols = [col for col in X.columns if X[col].isnull().any()]\r\n",
        "X.drop(drop_cols, axis = 1, inplace = True)\r\n",
        "\r\n",
        "# Split the data in train and validation sets\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, \r\n",
        "                                                  train_size = 0.8, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbzgoxdXqwU9"
      },
      "source": [
        "##### 1.2 Processing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5plhzUfmS1a"
      },
      "source": [
        "Now, the data needs to be processed, such that it suits for the analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SL1jHfCmaS-"
      },
      "source": [
        "# Cardinality refers to the number of unique values in a column\r\n",
        "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\r\n",
        "low_card_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 10 \r\n",
        "                                                    and X_train[cname].dtype == 'object']\r\n",
        "\r\n",
        "# Select numerical columns\r\n",
        "numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']]\r\n",
        "\r\n",
        "# Keep selected columns only\r\n",
        "my_cols = low_card_cols + numerical_cols\r\n",
        "X_train = X_train[my_cols].copy()\r\n",
        "X_val = X_val[my_cols].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsJPd_00q8Jp"
      },
      "source": [
        "For the Analysis, it is important to know which columns contain categorical data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYdIMPUBq_6J",
        "outputId": "4b0ac2d0-4512-4a0a-e3c2-5ac65ab4b416"
      },
      "source": [
        "# Get list of categorical variables\r\n",
        "cat_cols = (X_train.dtypes == 'object')   # Returns vector with true and false values if categorical\r\n",
        "object_cols = list(cat_cols[cat_cols].index)\r\n",
        "\r\n",
        "print('Categorical Variables:')\r\n",
        "print(object_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categorical Variables:\n",
            "['Type', 'Method', 'Regionname']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxVQHKCkxcMW"
      },
      "source": [
        "#### 2. Set up Regressor used to score Data processing Approaches\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKH473lUxbHt"
      },
      "source": [
        "# We are using a Random Forest Regressor to score the performance\r\n",
        "\r\n",
        "def score_mae(X_train, X_val, y_train, y_val):\r\n",
        "  # Develop Model and make Predictions\r\n",
        "  model = RandomForestRegressor(n_estimators = 100, random_state = 0)\r\n",
        "  model.fit(X_train,y_train)\r\n",
        "  preds = model.predict(X_val)\r\n",
        "\r\n",
        "  error = mean_absolute_error(y_val, preds)\r\n",
        "  return (error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUF3sNXhykIk"
      },
      "source": [
        "#### 3. Data Processing Approaches\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTdO7pWH5J0o"
      },
      "source": [
        "# Variable Containing the Score of each Approach\r\n",
        "method_score = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw32P6L_yqni"
      },
      "source": [
        "##### 3.1 Drop Columns with Categorical Values\r\n",
        "\r\n",
        "This approach drops any column, that contains a categorical value.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhwe7dYIyvew"
      },
      "source": [
        "# Dropping columns can be done using two methods\r\n",
        "\r\n",
        "## 1. Method: .drop() function of data frames\r\n",
        "\r\n",
        "# Assign object columns to drop_cols variable\r\n",
        "drop_cols = object_cols\r\n",
        "\r\n",
        "# Remove columns with missing values\r\n",
        "drop_X_train = X_train.drop(drop_cols, axis = 1)\r\n",
        "drop_X_val = X_val.drop(drop_cols, axis = 1)\r\n",
        "\r\n",
        "## 2. Method: dropping columns using the select_dtypes() method\r\n",
        "\r\n",
        "# Select only specified datatypes from a dataframe\r\n",
        "drop_X_train = X_train.select_dtypes(exclude = ['object'])\r\n",
        "drop_X_val = X_val.select_dtypes(exclude = ['object'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U26_8YrG4kBt",
        "outputId": "9c726272-ec99-441b-d75f-89afdf490a08"
      },
      "source": [
        "# Predict using the reduced feature set\r\n",
        "method_score.append(score_mae(drop_X_train, drop_X_val, y_train, y_val))\r\n",
        "print(method_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[175703.48185157913]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hd8vYJa5ZSF"
      },
      "source": [
        "##### 3.2 Use Label Encoding\r\n",
        "\r\n",
        "This approach uses sklearn's LabelEncoder function to label ordinal (rankable) values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTRTmQp56PKf"
      },
      "source": [
        "# Make a copy to avoid changing the original data\r\n",
        "label_X_train = X_train.copy()\r\n",
        "label_X_val = X_val.copy()\r\n",
        "\r\n",
        "# Define the Label Encoder\r\n",
        "label_encoder = LabelEncoder()\r\n",
        "\r\n",
        "# Apply the label encoder to each column with categorical data \r\n",
        "for col in object_cols: \r\n",
        "  label_X_train[col] = label_encoder.fit_transform(X_train[col])\r\n",
        "  label_X_val[col] = label_encoder.transform(X_val[col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk6_z50s7tNO",
        "outputId": "c86b86b2-0995-4ebe-a0f4-1706860bc554"
      },
      "source": [
        "# Predict using imputed dataset\r\n",
        "method_score.append(score_mae(label_X_train, label_X_val, y_train, y_val))\r\n",
        "print(method_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[175703.48185157913, 165936.40548390493]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qthj5NAP8DCV"
      },
      "source": [
        "##### 3.3 One-Hot Encoding\r\n",
        "\r\n",
        "Here, the one-hot encoding approach is being used, where columns are added for each individual categorical value, even within a column (i.e. column color, with entries: red, blue, yellow). Each unique entry results in a new column, with boolean values indicating, which colour was present in the original column (i.e. columns red, blue and yellow are created, which contrain ones, where the respective colour was present in the column color). To achieve this, the OneHotEncoder() function from sklearn is imported."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaJ3wRlkNErM"
      },
      "source": [
        "Before applying OH-encoding, one needs to check the number of columns and unique entries within these columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MknzzaO2NOdU",
        "outputId": "cfea27c5-6964-4ce4-d3ee-bfff69a2f30f"
      },
      "source": [
        "# Get number of unique entries in each column with categorical data\r\n",
        "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\r\n",
        "d = dict(zip(object_cols, object_nunique))\r\n",
        "\r\n",
        "# Print number of unique entries by column, in ascending order\r\n",
        "sorted(d.items(), key=lambda x: x[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Type', 3), ('Method', 5), ('Regionname', 8)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnQP4RPqNY9Q"
      },
      "source": [
        "> As can be seen, the number is not very high. OH-encoding should only be used for columns with a relatively small number of unique values, otherwise OH-encoding will result in a greatly expanded data set. In such instances, columns with a large number of unique variables should be either dropped, or label encoded. In this case here, the number of unique variables is small enough. \r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q3_CQoU8MVT"
      },
      "source": [
        "# Make a copy to avoid changing data when imputing \r\n",
        "X_train_plus = X_train.copy()\r\n",
        "X_val_plus = X_val.copy()\r\n",
        "\r\n",
        "# Make new columns indicating what will be imputed. df[col].isnull() returns true/false in each row of column col in dataframe df\r\n",
        "for col in drop_cols:\r\n",
        "  X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\r\n",
        "  X_val_plus[col + '_was_missing'] = X_val_plus[col].isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUjdh-mD9XYP"
      },
      "source": [
        "# Define the Encoder\r\n",
        "OH_encoder = OneHotEncoder(handle_unknown = \"ignore\", sparse = False)\r\n",
        "\r\n",
        "# Encode columns containing categorical values\r\n",
        "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\r\n",
        "OH_cols_val = pd.DataFrame(OH_encoder.transform(X_val[object_cols]))\r\n",
        "\r\n",
        "# Encoding returns a np array and therefore, index is lost\r\n",
        "OH_cols_train.index = X_train.index\r\n",
        "OH_cols_val.index = X_val.index\r\n",
        "\r\n",
        "# Remove categorical columns (will be replaced with one-hot encoding)\r\n",
        "num_X_train = X_train.drop(object_cols, axis = 1)\r\n",
        "num_X_val = X_val.drop(object_cols, axis = 1)\r\n",
        "\r\n",
        "# Combine Numerical and Encoded Categorical Values\r\n",
        "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis = 1)\r\n",
        "OH_X_val = pd.concat([num_X_val, OH_cols_val], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxMiP27N9rii",
        "outputId": "5eafea49-1be5-4ee0-de05-18ce861b156e"
      },
      "source": [
        "method_score.append(score_mae(OH_X_train, OH_X_val, y_train, y_val))\r\n",
        "print(method_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[175703.48185157913, 165936.40548390493, 166089.4893009678]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKbinFX3_R2D"
      },
      "source": [
        "##### 3.4 Conclusion\r\n",
        "\r\n",
        "As can be seen in this case, dropping categorical values performs significantly worse. In general, one-hot encoding will perform best, and dropping categorical columns will perform worst, however as always, this very much varies on a case by case basis, depending on the quality of the categorical data. When encoding data, it is important to check, if the categorical values present in the training data also appear in the validation/test data, otherwise an error will be returned. To prevent this, one should check the categorical values from the training and validation/test sets, identify the bad categories and remove them. Using the set() function is a way to identify bad columns. "
      ]
    }
  ]
}